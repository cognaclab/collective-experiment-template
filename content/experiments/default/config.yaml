# Default Experiment Configuration
experiment:
  name: "Collective Reward Multi-Armed Bandit"
  version: "1.0.0"
  author: "Wataru Toyokawa"
  
# Game Parameters
game:
  horizon: 20                    # number of trials per round
  total_game_rounds: 2           # number of rounds
  k_armed_bandit: 3              # number of bandit options
  max_choice_time: 10000         # time limit for decision making (ms)
  max_waiting_time: 10000        # maximum time in waiting foyer (ms)
  
# Group Settings  
groups:
  max_group_size: 5              # maximum size per group
  min_group_size: 2              # minimum group size
  
# Payoff Environment Settings
environments:
  static:
    prob_0: [0.7, 0.4, 0.3]     # environment 0 probabilities
  dynamic:
    prob_1: [0.8, 0.3, 0.3]     # environment 1 probabilities  
    prob_2: [0.3, 0.3, 0.8]     # environment 2 probabilities
    prob_3: [0.8, 0.3, 0.3]     # environment 3 probabilities
    prob_4: [0.3, 0.8, 0.3]     # environment 4 probabilities
    change_points: [17, 29, 45]  # trials where environment changes
    
# Task Order
task_order: ['static', 'dynamic'] # randomized environmental order

# Debug Settings
debug:
  subject_exceptions: ['INHOUSETEST3', 'wataruDebug']

# Payment Settings
payment:
  flat_fee: 1.0                  # GBP base payment
  completion_fee: 0              # additional completion bonus